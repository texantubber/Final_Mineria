---
title: "Preparación de los Datos"
output: 
  html_document:
    toc: TRUE
    toc_depth: 4
---
```{r}
t<-Sys.time()
```

```{r setup, include=FALSE, message=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(DT)
library(scales)
library(pryr)
```

```{r Utils, message=FALSE, warning=FALSE}
source('02_Utils.R')
```


# Selección de los datos 

Hasta el momento, se seleccionan todas las variables disponibles de la fase **Entendiendo los Datos**. Cabe destacar que las variables de nombre de artículo, nombre de categoría y nombre de tienda se conservan con fines de interpretabilidad, pero de ser necesario se eliminarán de las bases para acelerar el proceso y liberar memoria.  

```{r}
# Cargaos los datos de entrenamiento obtenidos de la fase anterior. 
datos_train<-readRDS('Datos_trad/train_trad.rds')

# Carggamos los catálogos de artículos y tiendas
datos_items<-readRDS('Datos_trad/datos_items.rds')
shops<-readRDS('Datos_trad/shops.rds')

```

Esta base de datos tiene las siguientes variables: 

1. *date*: fecha en que se registró la compra/devolución en el formato dd/mm/yyyy. 

2. *date_block_num*: número consecutivo para el mes de venta. Es decir, enero 2013 es igual a 0, febrero 2013 es igual a 1, ..., octubre 2015 es igual a 33. 

3. *shop_id*: identificador único de las tiendas de 1C. 

4. *item_id*: identificador único del artículo. 
 
5. *item_price*: precio en el que se vendió el artículo. No se menciona la moneda en que realizó la transacción, posiblemente fueron dólares o rublos rusos. 

6. *item_cnt_day*: número de unidades vendidas del artículo. Números negativos indican una devolución del artículo. Se va a predecir una cantidad mensual de esta medida. 

7. *item_name*: nombre del artículo (en ruso). 

8. *item_category_id*: identificador único de la categoría a la que pertenece el artículo.
    
9. *item_category_name*: nombre de la categoría (en ruso). 
    
10. *item_cateogry_id*: identificador único de la categoría.
    
11. *ID*: identificador único para la dupla (tienda,artículo). 


# Limpieza de datos

## Tipo de variables 

Hechamos un vistazo a la base de datos obtenida del proceso de comprensión y exploración de los datos. 

```{r }

glimpse(datos_train)

```

La variable *date* no es reconocida como fecha y la variable *tiem_cnt_day* no es reconocida como entero. Se hacen estos cambios. 

```{r}
# Se cambia la variable date a formato fechay la variable item_cnt_day a formato entero 
datos_train<-datos_train%>%
  mutate(date=as.Date(date,format="%d.%m.%Y"),
         item_cnt_day=as.integer(item_cnt_day))%>%
  select(date,everything())
```


## Datos faltantes

Checamos si existen datos faltantes en el set de entrenamiento. 
```{r DatosFaltantes}
# Summary para detectar presencia de NA's
summary(datos_train)
```

No se tienen valores faltantes en el set de entrenamiento. 


## Valores únicos por variable. 

Se verifican los valores únicos por variable para ver si existen observaciones con errores o si vale la pena categorizar alguna variable. 


Para las variables *date*, *date_block_num*, *shop_id*, *item_id*, *item_name*,*item_category_id*, *item_category_name*, *shop_name* y *ID* no es necesario checar los valores únicos ya se son identificadores de fecha, tienda, categoría o artículo. 


Las variables que sí se deben revisar son *item_price* y *item_cnt_day*. 


### Precio por artículo 

```{r}
length(unique(datos_train$item_price))
```

Para la variable *item_price* se tienen 19,993 precios únicos. Esto no es sorpresa ya que la variable es de tipo double. Veamos un summary de esta variable para poder decidir sobre su distribución y posible categorización. 

```{r}
summary(datos_train$item_price)
```

En primer lugar, se puede notar que existen precios negativos, lo cual no es factible. En segundo lugar la diferencia entre el tercer cuantil y el máximo es muy grande, esto es señal de un dato atípico. 


Veamos los 20 valores más grandes del precio de los artículos.

```{r OutlierPrice}
head(sort(datos_train$item_price,decreasing = TRUE),20)
```

Efectivamente se trata de un valor atípico. Veamos de qué producto se trata. 

```{r OutlierPrice2}

datos_train$item_name[which(datos_train$item_price==307980)]
```

Investigando en 1C y, asumiendo que el precio está en dólares, se llegó a la conclusión de que se escribó mal el precio de este artículo y sería razonable pensar que el verdadero precio es de $3,079.80 dólares. Por lo tanto, se sustitye dico valor. 

```{r}
datos_train$item_price[which(datos_train$item_price==307980)]<-3079.80
```


En cuanto a los precios negativos, veamos cuantos son. 

```{r}
length(which(datos_train$item_price<0))
```

Sólo se tiene un artículo que tiene precio negativo. Busquemos si en la misma fecha se vendió el mismo artículo para extraer el verdadero precio. 

```{r NegPrice, warning=FALSE, message=FALSE}
# extraemos los items devueltos
item_id_pneg<-datos_train%>%
  filter(item_price<0)%>%
  select(item_id)%>%
  unique()%>%
  as.numeric

# extraemos la fecha de devolucion
date_pneg<-datos_train%>%
  filter(item_price<0)%>%
  select(date)%>%
  unique()

# Extraemso el precio promedio del objeto en la misma fecha
items_ppos<-datos_train%>%
  filter(item_id==item_id_pneg)%>%
  filter(date==date_pneg)%>%
  filter(item_price!=-1)%>%
  select(date, item_name, item_price)

datatable(items_ppos)

```

Se tienen otros tres articulos iguales vendidos en la misma fecha. Por lo tanto se reemplaza el precio negativo con el promedio del precio de estos artículos. 

```{r}
# Reemplazamos el precio -1 con el promedio 
datos_train$item_price[which(datos_train$item_price==-1)]<-mean(items_ppos$item_price)
```

```{r}

# Veamos como quedó la distribución del precio de los articulos. 
summary(datos_train$item_price)

# Histograma del precio de los artículos.
ggplot(datos_train,aes(item_price))+
  geom_histogram(binwidth = 1000)+
  ggtitle('Item Price Distirbution')+
  xlab('Item Price')+
  ylab('Count')
  
```

Todavía existe una gran diferencia entre el tercer cuantil y el valor máximo del precio. Sin embargo, dado aue la tarea es predecir el número de articulos vendido cada mes de cada tipo en cada tienda, por el momento, no se realiza ninguna estrategia de categorización del precio. De ser necesario, se realizará en el pipeline de python al modelar. 


#### Número de unidades vendidas/devueltas. 

Verificamos los valores únicos para la variable *item_cnt_day*. 

```{r}
sort(unique(datos_train$item_cnt_day),decreasing = TRUE)
```

El número de unidades vendidas por artículo va desde 1 hasta 2169. El número de unidades devueltas por artículo va desde 1 hasta 22. No parece haber nada incorrecto en esta variable. 


Veamos que artículos fueron los más vendidos. 

```{r}
cnt_day_mayores<-sort(unique(datos_train$item_cnt_day),decreasing = TRUE)[1:10]

datos_train$item_name[match(cnt_day_mayores,datos_train$item_cnt_day)]
```
 
Al parecer, "Delivery to the point of delivery (Boxberry)" y "Ticket &quot;IgroMir 2015&quot; - October 3, 2015 (website) [Digital version]" son de los artículos más devueltos. 


# Ingeniería de características

Para hacer el feature engineering nos olivdamos momentáneamente de los nombres de los artículos, categorías y tiendas y sólo trabajamos con el identificador de la tienda y del artículo, la fecha, el consecutivo de la fecha, el precio y las ventas. 


## Separar día mes y año 

De la variable *date* se puede separar el día, mes y año. Esto será de utilidad para los agregados mensuales. 

```{r}
datos_train<-datos_train%>%
  dplyr::select(date,date_block_num,shop_id,item_id,item_price,item_cnt_day)%>%
  mutate(day=as.integer(substring(as.character(date),9,10)),
         month=as.integer(substring(as.character(date),6,7)),
         year=as.integer(substring(as.character(date),1,4)))%>%
  select(date,day,month,year,everything())

head(datos_train)
```


```{r}
unique(datos_train$year)
```

La base de datos de entrenamiento tiene información diaria para tres años: 2013-2015. 


## Agregados Mensuales

La tarea es predecir las ventas mensuales por dupla (tienda, artículo); por lo tanto, se hace un agregado mensual de las variables. 
  * Para el número de artículos vendidos, se agrega calculando la suma de todos los artículos vendidos en el mismo mes, en la misma tienda.
  * Para el precio del artículo vendido, se agrega calculando el precio promedio de todos los artículos vendidos en el mismo mes, en la misma tienda. 


```{r AgregadoMensual, cache=TRUE}

# hacemos el agregado mensual por dupla (tienda,art) y fecha mensual (date_block_num)
train_mensuales<-datos_train%>%
  group_by(date_block_num,shop_id,item_id)%>%
  summarise(item_price_mean=mean(item_price),
            item_cnt_month=sum(item_cnt_day))

# Ordenaos por dupla 
train_mensuales<-arrange(train_mensuales,date_block_num,shop_id,item_id)

# guardar datos
saveRDS(train_mensuales,"Datos_clean/train_mensuales.rds")

# eliminar datos train para liberar memoria
mem_change(rm(datos_train))

```

Hechamos un vistazo a los datos mensuales
```{r}
glimpse(train_mensuales)
```

Un problema es que hay duplas (tienda, artículo) para las cuales no hay registro en algunos meses. Es decir, no en todos los meses del año se vendieron todos los artículos en todas las tiendas. Por lo tanto, no se tienen las series de tiempo completas por lo que hay que completarlas de tal manera que el algoritmo sea capaz de aprender estas irregularidades en las ventas. 

## Completar series de tiempo por dupla (tienda, artículo)

Creamos el grid con todas las posibles combinaciones por mes, tienda y artículo. 

```{r}
#Creamos grid de date_block_num, shop_id, item_id
train_mensuales_completo<-list(date_block_num=0:33,
                               shop_id=unique(shops$shop_id),
                               item_id=unique(datos_items$item_id))%>%
  expand.grid

dim(train_mensuales_completo)

```

Hacemos un merge de los datos mensuales observados obtenidos en el paso anterior con este grid. 

```{r}
# Hacemos left join de los datos mensuales 
train_mensuales_completo<-left_join(train_mensuales_completo,train_mensuales,by=c('date_block_num','shop_id','item_id'))

mem_change(rm(train_mensuales))

```

```{r}
glimpse(train_mensuales_completo)
```

Agregamos el item_category_id para poder hacer agregaciones por categorías de artículos. 

```{r}
# Agregamos la variable category_id
train_mensuales_completo<-train_mensuales_completo%>%
  left_join(datos_items,key='item_id')%>%
  select(-c(item_name,item_category_name))

```

```{r}
glimpse(train_mensuales_completo)
```


Unicamente tenemos missings en item_price_mean y item_cnt_month. Los missings en item_cnt_month corresponden a que no hubo ventas para ese artículo en ese mes en esa tienda; porlo tanto, sustituimos estos NA's con 0.

```{r}
train_mensuales_completo$item_cnt_month[which(is.na(train_mensuales_completo$item_cnt_month))]<-0
```

Para arreglar los NA's del precio, hacemos nuevas variables. Calculamos:
* el precio promedio por artículo (*item_price_mean_art*),
* la cantidad vendida por artículo (*item_cnt_art*), 
* la cantidad vendida promedio por artículo (*item_cnt_mean_art*), 
* el precio promedio por categoría (*item_price_mean_cat*),
* la cantidad vendida por categoría (*item_cnt_cat*), 
* la cantidad vendida promedio por categoría (*item_cnt_mean_art*), 
* el precio promedio por tienda (*item_price_mean_shop*),
* la cantidad vendida por tienda (*item_cnt_shop*), 
* la cantidad vendida promedio por tienda (*item_cnt_mean_art*), 

```{r}
# Por artículo
mean_price_item<-train_mensuales_completo%>%
  group_by(item_id)%>%
  summarise(item_price_mean_art=mean(item_price_mean,na.rm=TRUE),
            item_cnt_art=sum(item_cnt_month),
            item_cnt_mean_art=mean(item_cnt_month,na.rm=TRUE))


# Por categoria
mean_price_cat<-train_mensuales_completo%>%
  group_by(item_category_id)%>%
  summarise(item_price_mean_cat=mean(item_price_mean,na.rm=TRUE),
            item_cnt_cat=sum(item_cnt_month),
            item_cnt_mean_cat=mean(item_cnt_month,na.rm=TRUE))

# Por tienda
mean_price_shop<-train_mensuales_completo%>%
  group_by(shop_id)%>%
  summarise(item_price_mean_shop=mean(item_price_mean,na.rm=TRUE),
            item_cnt_shop=sum(item_cnt_month),
            item_cnt_mean_shop=mean(item_cnt_month,na.rm=TRUE))
```

Ahora hacemos un left join de estos nuevos precios con el data set completo 

```{r}
# Juntamos los distintos precios 
train_mensuales_completo<-train_mensuales_completo%>%
  left_join(mean_price_item, key='item_id')%>%
  left_join(mean_price_cat, key='item_category_id')%>%
  left_join(mean_price_shop,key='shop_id')

mem_change(rm(mean_price_item))
mem_change(rm(mean_price_cat))
mem_change(rm(mean_price_shop))
```

```{r}
glimpse(train_mensuales_completo)
```

```{r}
summary(train_mensuales_completo)
```

Ya solo tenemos NA's en el precio promedio original y en el precio promedio por artículo. El primero no se va a utilizar ya que sólo sirvió para construir el resto de las características. En cuanto al segundo, se imputa con la mediana debido a la existencia de datos atípicos en el precio. 

```{r}
train_mensuales_completo<-train_mensuales_completo%>%
  dplyr::select(-item_price_mean)

train_mensuales_completo$item_price_mean_art[which(is.na(train_mensuales_completo$item_price_mean_art))]<-median(train_mensuales_completo$item_price_mean_art,na.rm=TRUE)
```

## Rezagos de las variables 

Dado que en la verdadera tarea de predicción no se van a tener los datos actuales, sino los datos de los meses previos, creamos rezagos de las variables actuales: mensual, bimestral, trimestral, semestral. 


```{r Lags1}

# # Creamos lags de variables. 
# train_mensuales_completo<-train_mensuales_completo%>%
#   mutate(item_price_mean_art_l1=lag(item_price_mean_art),
#          item_price_mean_art_l3=lag(item_price_mean_art,3),
#          item_price_mean_art_l12=lag(item_price_mean_art,12),
#          item_cnt_art_l1=lag(item_cnt_art),
#          item_cnt_art_l3=lag(item_cnt_art,3),
#          item_cnt_art_l12=lag(item_cnt_art,12),
#          item_cnt_mean_art_l1=lag(item_cnt_mean_art),
#          item_cnt_mean_art_l3=lag(item_cnt_mean_art,3),
#          item_cnt_mean_art_l12=lag(item_cnt_mean_art,12),
#          item_price_mean_cat_l1=lag(item_price_mean_cat),
#          item_price_mean_cat_l3=lag(item_price_mean_cat,3),
#          item_price_mean_cat_l12=lag(item_price_mean_cat,12),
#          item_cnt_cat_l1=lag(item_cnt_cat),
#          item_cnt_cat_l3=lag(item_cnt_cat,3),
#          item_cnt_cat_l12=lag(item_cnt_cat,12),
#          item_cnt_mean_art_l1=lag(item_cnt_mean_art),
#          item_cnt_mean_art_l3=lag(item_cnt_mean_art,3),
#          item_cnt_mean_art_l12=lag(item_cnt_mean_art,12),
#          item_price_mean_shop_l1=lag(item_price_mean_shop),
#          item_price_mean_shop_l3=lag(item_price_mean_shop,3),
#          item_price_mean_shop_l12=lag(item_price_mean_shop,12),
#          item_cnt_shop_l1=lag(item_cnt_shop),
#          item_cnt_shop_l3=lag(item_cnt_shop,3),
#          item_cnt_shop_l12=lag(item_cnt_shop,12),
#          item_cnt_mean_shop_l1=lag(item_cnt_mean_shop),
#          item_cnt_mean_shop_l3=lag(item_cnt_mean_shop,3),
#          item_cnt_mean_shop_l12=lag(item_cnt_mean_shop,12))

# Creamos lags de variables. 
train_mensuales_completo<-train_mensuales_completo%>%
  mutate(item_price_mean_art_l1=lag(item_price_mean_art),
         item_price_mean_art_l12=lag(item_price_mean_art,12),
         item_cnt_art_l1=lag(item_cnt_art),
         item_cnt_art_l12=lag(item_cnt_art,12),
         item_cnt_mean_art_l1=lag(item_cnt_mean_art),
         item_cnt_mean_art_l12=lag(item_cnt_mean_art,12),
         item_price_mean_cat_l1=lag(item_price_mean_cat),
         item_price_mean_cat_l12=lag(item_price_mean_cat,12),
         item_cnt_cat_l1=lag(item_cnt_cat),
         item_cnt_cat_l12=lag(item_cnt_cat,12),
         item_cnt_mean_art_l1=lag(item_cnt_mean_art),
         item_cnt_mean_art_l12=lag(item_cnt_mean_art,12),
         item_price_mean_shop_l1=lag(item_price_mean_shop),
         item_price_mean_shop_l12=lag(item_price_mean_shop,12),
         item_cnt_shop_l1=lag(item_cnt_shop),
         item_cnt_shop_l12=lag(item_cnt_shop,12),
         item_cnt_mean_shop_l1=lag(item_cnt_mean_shop),
         item_cnt_mean_shop_l12=lag(item_cnt_mean_shop,12))

# saveRDS(train_mensuales_completo,"Datos_clean/train_mensuales_completo.rds")

```

Imputamos los NA's de los rezagos (primeros $n$ valores para rezago de tamaño $n$) con el primer valor observado (correspondiente a la observación $n+1$).

```{r}
# Imputamos valores
train_mensuales_completo<-apply(train_mensuales_completo,2,imputarLags)

saveRDS(train_mensuales_completo,"Datos_clean/train_mensuales_completo.rds")

```


```{r}
saveRDS(train_mensuales_completo,"Datos_clean/train_mensuales_completo.rds")
```


<!-- ## Escalamiento del número de artículos vendidos -->

<!-- Para efectos de la competencia en Kaggle, el número de artículos vendidos debe estar entre 0 y 20. Por lo tanto se escala la variable *item_cnt_month* -->

<!-- ```{r, eval=FALSE, include=FALSE} -->
<!-- train_mensuales_completo$item_cnt_month_rescale<-rescale(train_mensuales$item_cnt_month,to=c(0,20)) -->

<!-- saveRDS(train_mensuales_completo,"Datos_clean/train_mensuales_completo.rds") -->

<!-- ``` -->



```{r}
t<-t-Sys.time()

t
```

